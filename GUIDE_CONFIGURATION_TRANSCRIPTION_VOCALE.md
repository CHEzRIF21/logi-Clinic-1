# üé§ Guide de Configuration - Transcription Vocale avec API

Ce guide vous explique comment configurer la transcription vocale en utilisant une API externe (OpenAI Whisper, Google Speech-to-Text, Azure Speech, etc.).

## üìã Pr√©requis

- Une cl√© API pour un service de transcription vocale
- Node.js et npm install√©s
- Le serveur backend configur√©

## üîë Configuration de la Cl√© API

### Option 1: Via fichier .env (Recommand√©)

Cr√©ez ou modifiez le fichier `.env` √† la racine du projet `server/` :

```env
# Configuration Transcription Vocale
SPEECH_TO_TEXT_API_KEY=votre-cl√©-api-ici
SPEECH_TO_TEXT_PROVIDER=openai
SPEECH_TO_TEXT_API_URL=
```

### Option 2: Via docker-compose.yml

Ajoutez les variables dans `docker-compose.yml` :

```yaml
server:
  environment:
    SPEECH_TO_TEXT_API_KEY: votre-cl√©-api-ici
    SPEECH_TO_TEXT_PROVIDER: openai
    SPEECH_TO_TEXT_API_URL: # Optionnel, URL personnalis√©e
```

### Option 3: Variables d'environnement syst√®me

```bash
export SPEECH_TO_TEXT_API_KEY="votre-cl√©-api-ici"
export SPEECH_TO_TEXT_PROVIDER="openai"
```

## üîß Providers Support√©s

### 1. OpenAI Whisper (Recommand√©)

```env
SPEECH_TO_TEXT_PROVIDER=openai
SPEECH_TO_TEXT_API_KEY=sk-votre-cl√©-openai
```

**Avantages :**
- Tr√®s pr√©cis
- Supporte de nombreuses langues
- Mod√®le : `whisper-1`

**Obtenir une cl√© :**
1. Allez sur https://platform.openai.com/api-keys
2. Cr√©ez un compte ou connectez-vous
3. G√©n√©rez une nouvelle cl√© API
4. Copiez la cl√© (commence par `sk-`)

### 2. Google Speech-to-Text

```env
SPEECH_TO_TEXT_PROVIDER=google
SPEECH_TO_TEXT_API_KEY=votre-cl√©-google-cloud
```

**Avantages :**
- Int√©gration Google Cloud
- Supporte le streaming
- Bonne qualit√©

**Obtenir une cl√© :**
1. Allez sur https://console.cloud.google.com/
2. Cr√©ez un projet ou s√©lectionnez-en un
3. Activez l'API Speech-to-Text
4. Cr√©ez une cl√© API dans "Identifiants"

### 3. Azure Speech Services

```env
SPEECH_TO_TEXT_PROVIDER=azure
SPEECH_TO_TEXT_API_KEY=votre-cl√©-azure
AZURE_SPEECH_REGION=francecentral
```

**Avantages :**
- Int√©gration Microsoft Azure
- Supporte plusieurs r√©gions
- Bonne qualit√©

**Obtenir une cl√© :**
1. Allez sur https://portal.azure.com/
2. Cr√©ez une ressource "Speech Services"
3. Copiez la cl√© et la r√©gion

### 4. API Personnalis√©e

```env
SPEECH_TO_TEXT_PROVIDER=custom
SPEECH_TO_TEXT_API_KEY=votre-cl√©
SPEECH_TO_TEXT_API_URL=https://votre-api.com/transcribe
```

**Format attendu de la r√©ponse :**
```json
{
  "text": "texte transcrit",
  "confidence": 0.95,
  "language": "fr-FR"
}
```

## üì¶ Installation des D√©pendances

Dans le r√©pertoire `server/` :

```bash
npm install multer form-data
npm install --save-dev @types/multer
```

## üöÄ Utilisation

### Dans le Frontend

Le hook `useSpeechRecognitionAPI` utilise automatiquement le backend si configur√© :

```typescript
import { useSpeechRecognitionAPI } from '@/hooks/useSpeechRecognitionAPI';

const MyComponent = () => {
  const {
    isListening,
    transcript,
    error,
    startListening,
    stopListening,
    resetTranscript,
    isSupported,
    isUsingAPI, // true si utilise le backend API
  } = useSpeechRecognitionAPI('fr-FR', true, true, true);

  return (
    <div>
      <button onClick={startListening}>D√©marrer</button>
      <button onClick={stopListening}>Arr√™ter</button>
      <p>{transcript}</p>
    </div>
  );
};
```

### V√©rifier le Statut

```bash
# V√©rifier si le service est configur√©
curl http://localhost:3000/api/speech-to-text/status
```

R√©ponse :
```json
{
  "configured": true,
  "provider": "openai",
  "message": "Service de transcription disponible"
}
```

### Tester la Transcription

```bash
# Envoyer un fichier audio pour transcription
curl -X POST http://localhost:3000/api/speech-to-text/transcribe \
  -F "audio=@votre-fichier.webm" \
  -F "language=fr-FR"
```

## üîÑ Migration depuis l'API du Navigateur

Si vous utilisez actuellement `useSpeechRecognition`, remplacez-le par `useSpeechRecognitionAPI` :

**Avant :**
```typescript
import { useSpeechRecognition } from '@/hooks/useSpeechRecognition';
```

**Apr√®s :**
```typescript
import { useSpeechRecognitionAPI } from '@/hooks/useSpeechRecognitionAPI';
```

Le hook fonctionne de la m√™me mani√®re, mais utilise le backend si disponible.

## üêõ D√©pannage

### Le service n'est pas configur√©

**Erreur :** `Service de transcription non configur√©`

**Solution :**
1. V√©rifiez que les variables d'environnement sont d√©finies
2. Red√©marrez le serveur
3. V√©rifiez le statut : `GET /api/speech-to-text/status`

### Erreur d'authentification API

**Erreur :** `Erreur API OpenAI` ou similaire

**Solution :**
1. V√©rifiez que votre cl√© API est correcte
2. V√©rifiez que votre cl√© API n'a pas expir√©
3. V√©rifiez les quotas de votre compte API

### Le microphone n'est pas accessible

**Erreur :** `Permission d'acc√®s au microphone refus√©e`

**Solution :**
1. Autorisez l'acc√®s au microphone dans les param√®tres du navigateur
2. Utilisez HTTPS en production (requis pour l'acc√®s microphone)

### Format audio non support√©

**Erreur :** `Format audio non support√©`

**Solution :**
Les formats support√©s sont : webm, wav, mp3, ogg, m4a

## üìù Exemples de Configuration Compl√®te

### Configuration OpenAI

```env
SPEECH_TO_TEXT_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
SPEECH_TO_TEXT_PROVIDER=openai
```

### Configuration Google

```env
SPEECH_TO_TEXT_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
SPEECH_TO_TEXT_PROVIDER=google
```

### Configuration Azure

```env
SPEECH_TO_TEXT_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
SPEECH_TO_TEXT_PROVIDER=azure
AZURE_SPEECH_REGION=francecentral
```

## ‚úÖ Checklist de Configuration

- [ ] Cl√© API obtenue et copi√©e
- [ ] Variables d'environnement configur√©es
- [ ] D√©pendances install√©es (`multer`, `form-data`)
- [ ] Serveur red√©marr√©
- [ ] Statut v√©rifi√© : `GET /api/speech-to-text/status`
- [ ] Test de transcription effectu√©
- [ ] Hook frontend mis √† jour si n√©cessaire

## üîí S√©curit√©

‚ö†Ô∏è **Important :** Ne commitez jamais votre cl√© API dans le d√©p√¥t Git !

1. Ajoutez `.env` √† `.gitignore`
2. Utilisez des variables d'environnement syst√®me en production
3. Limitez les permissions de votre cl√© API
4. Surveillez l'utilisation de votre cl√© API

## üìö Ressources

- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference/audio)
- [Google Speech-to-Text](https://cloud.google.com/speech-to-text/docs)
- [Azure Speech Services](https://azure.microsoft.com/services/cognitive-services/speech-services/)

---

**Note :** Si aucune cl√© API n'est configur√©e, le syst√®me utilisera automatiquement l'API Web Speech Recognition du navigateur (si disponible).

